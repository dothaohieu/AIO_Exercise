{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a\n",
    "2. P(yes | X) = P(X|yes)*P(yes) / P(X) <br>\n",
    "P(X) = P(X|yes)*P(yes) + P(X|no)*P(no) <br>\n",
    "P(yes) = 0.6 <br>\n",
    "P(no) = 0.4 <br>\n",
    "P(X|yes) = 1/6*1/2*2/6*1/6 <br>\n",
    "P(X|no) = 1/2*1/4*3/4*1/2 <br>\n",
    "=> P(yes | X) = (1/6*1/2*2/6*1/6*6/10)/(1/6*1/2*2/6*1/6*6/10 + 1/2*1/4*3/4*1/2*4/10) = 4/31\n",
    "P(no | X) = 27/31\n",
    "=> B\n",
    "3. C\n",
    "4. B\n",
    "5. A\n",
    "6. C\n",
    "7. D\n",
    "8. A\n",
    "9. D\n",
    "10. A\n",
    "11. A\n",
    "12. B\n",
    "13. A\n",
    "14. A\n",
    "15. B\n",
    "16. C\n",
    "17. D\n",
    "18. A\n",
    "19. A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(on time) 0.0\n",
      "P(late) 0.0\n",
      "x1 =  ['holiday' 'saturday' 'sunday' 'weekday']\n",
      "x2 =  ['autumn' 'spring' 'summer' 'winter']\n",
      "x3 =  ['high' 'none' 'normal']\n",
      "x4 =  ['holiday' 'saturday' 'sunday' 'weekday']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0025464320000000004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data2 = np.array([\n",
    "    ['weekday', 'spring', 'none', 'none', 'on time'],\n",
    "    ['weekday', 'winter', 'none', 'slight', 'on time'],\n",
    "    ['weekday', 'winter', 'none', 'none', 'on time'],\n",
    "    ['holiday', 'winter', 'high', 'slight', 'late'],\n",
    "    ['saturday', 'summer', 'normal', 'none', 'on time'],\n",
    "    ['weekday', 'autumn', 'normal', 'none', 'very late'],\n",
    "    ['holiday', 'summer', 'high', 'slight', 'on time'],\n",
    "    ['sunday', 'summer', 'normal', 'none', 'on time'],\n",
    "    ['weekday', 'winter', 'high', 'heavy', 'very late'],\n",
    "    ['weekday', 'summer', 'none', 'slight', 'on time'],\n",
    "    ['saturday', 'spring', 'high', 'heavy', 'cancelled'],\n",
    "    ['weekday', 'summer', 'high', 'slight', 'on time'],\n",
    "    ['weekday', 'winter', 'normal', 'none', 'late'],\n",
    "    ['weekday', 'summer', 'high', 'none', 'on time'],\n",
    "    ['weekday', 'winter', 'normal', 'heavy', 'very late'],\n",
    "    ['saturday', 'autumn', 'high', 'slight', 'on time'],\n",
    "    ['weekday', 'autumn', 'none', 'heavy', 'on time'],\n",
    "    ['holiday', 'spring', 'normal', 'slight', 'on time'],\n",
    "    ['weekday', 'spring', 'normal', 'none', 'on time'],\n",
    "    ['weekday', 'spring', 'normal', 'heavy', 'on time']\n",
    "])\n",
    "def compute_prior_probablity(train_data):\n",
    "  y_unique = ['on time', 'late', 'very late', 'cancelled']\n",
    "  prior_probability = np.zeros(len(y_unique))\n",
    "  for i in range(0,len(y_unique)):\n",
    "    prior_probability[i]=len(np.where(train_data[:,1] == y_unique[i])[0])/len(train_data)\n",
    "  return prior_probability\n",
    "prior_probablity = compute_prior_probablity(data2)\n",
    "print(\"P(on time)\", prior_probablity[0])\n",
    "print(\"P(late)\", prior_probablity[1])\n",
    "\n",
    "def compute_conditional_probability(train_data):\n",
    "  y_unique = ['on time', 'late', 'very late', 'cancelled']\n",
    "  conditional_probability = []\n",
    "  list_x_name = []\n",
    "  for i in range(0,train_data.shape[1]-1):\n",
    "    x_unique = np.unique(train_data[:,i])\n",
    "\n",
    "    list_x_name.append(x_unique)\n",
    "\n",
    "    x_conditional_probability = np.zeros((len(y_unique),len(x_unique)))\n",
    "    for j in range(0,len(y_unique)):\n",
    "      for k in range(0,len(x_unique)):\n",
    "        x_conditional_probability[j,k]= len(np.where((train_data[:,i] == x_unique[k]) & (train_data[:,4] == y_unique[j]))[0])/len(np.where(train_data[:,4] == y_unique[j])[0])\n",
    "\n",
    "    conditional_probability.append(x_conditional_probability)\n",
    "  return conditional_probability, list_x_name\n",
    "\n",
    "_, list_x_name  = compute_conditional_probability(data2)\n",
    "print(\"x1 = \",list_x_name[0])\n",
    "print(\"x2 = \",list_x_name[1])\n",
    "print(\"x3 = \",list_x_name[2])\n",
    "print(\"x4 = \",list_x_name[0])\n",
    "\n",
    "def train_naive_bayes(train_data):\n",
    "    # Step 1: Calculate Prior Probability\n",
    "    prior_probability = compute_prior_probablity(train_data)\n",
    "\n",
    "    # Step 2: Calculate Conditional Probability\n",
    "    conditional_probability, list_x_name  = compute_conditional_probability(train_data)\n",
    "\n",
    "    return prior_probability,conditional_probability, list_x_name\n",
    "\n",
    "prior_probability,conditional_probability, list_x_name = train_naive_bayes(data2)\n",
    "\n",
    "def get_index_from_value(feature_name, list_features):\n",
    "  return np.where(list_features == feature_name)[0][0]\n",
    "\n",
    "conditional_probability, list_x_name  = compute_conditional_probability(data2)\n",
    "# Compute P(\"Outlook\"=\"Sunny\"|Play Tennis\"=\"Yes\")\n",
    "x1=get_index_from_value(\"weekday\",list_x_name[0])\n",
    "x2=get_index_from_value(\"winter\",list_x_name[1])\n",
    "x3=get_index_from_value(\"high\",list_x_name[2])\n",
    "x4=get_index_from_value(\"heavy\",list_x_name[3])\n",
    "np.round(conditional_probability[0][0, x1],2)*np.round(conditional_probability[1][0, x2],2)*np.round(conditional_probability[2][0, x3],2)*np.round(conditional_probability[3][0, x4],2)*14/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "def create_train_data_iris():\n",
    "  data = np.genfromtxt(\"iris_1D.csv\", delimiter=\",\", dtype=str)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prior_probablity_iris(train_data):\n",
    "  y_unique = np.unique(train_data[:,1])\n",
    "  prior_probability = np.zeros(len(y_unique))\n",
    "  for i in range(0,len(y_unique)):\n",
    "    prior_probability[i]=len(np.where(train_data[:,1] == y_unique[i])[0])/len(train_data)\n",
    "  return prior_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to compute the conditional probabilities\n",
    "#input: train data\n",
    "#output: conditional probabilities and list of feature names\n",
    "def compute_conditional_probability_iris(train_data):\n",
    "  y_unique = np.unique(train_data[:,1]) # 0 for Setosa, 1 for Versicolour, 2 for Virginica\n",
    "  conditional_probability = []\n",
    "  for i in range(0,train_data.shape[1]-1):\n",
    "    x_conditional_probability = np.zeros((len(y_unique), 2))\n",
    "    for j in range(0,len(y_unique)):\n",
    "        mean = np.mean((train_data[:,i][np.where(train_data[:,1] == y_unique[j])]).astype(float))\n",
    "        sigma =  np.std((train_data[:,i][np.where(train_data[:,1] == y_unique[j])]).astype(float))\n",
    "        sigma = sigma * sigma\n",
    "        x_conditional_probability[j]= [mean, sigma]\n",
    "\n",
    "    conditional_probability.append(x_conditional_probability)\n",
    "  return conditional_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#Define the Gaussian function\n",
    "def gauss(x, mean, sigma):\n",
    "  result = (1.0 / (np.sqrt(2*math.pi*sigma))) \\\n",
    "  * (np.exp(-(float(x) - mean) ** 2 / (2 * sigma)))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Train Naive Bayes Model\n",
    "###########################\n",
    "def train_gaussian_naive_bayes(train_data):\n",
    "    # Step 1: Calculate Prior Probability\n",
    "    prior_probability = compute_prior_probablity_iris(train_data)\n",
    "    print(prior_probability)\n",
    "\n",
    "    # Step 2: Calculate Conditional Probability\n",
    "    conditional_probability  = compute_conditional_probability_iris(train_data)\n",
    "\n",
    "    return prior_probability,conditional_probability\n",
    "\n",
    "# data = create_train_data_iris()\n",
    "# conditional_probability = train_gaussian_naive_bayes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Prediction\n",
    "####################\n",
    "def prediction_iris(X,  prior_probability, conditional_probability):\n",
    "\n",
    "    p0=prior_probability[0] \\\n",
    "    *gauss(X[0], conditional_probability[0][0][0],conditional_probability[0][0][1])  \\\n",
    "    # *gauss(X[1], conditional_probability[1][0][0],conditional_probability[1][0][1])  \\\n",
    "    # *gauss(X[2], conditional_probability[2][0][0],conditional_probability[2][0][1])  \\\n",
    "    # *gauss(X[3], conditional_probability[3][0][0],conditional_probability[3][0][1])\n",
    "    print(p0)\n",
    "    p1=prior_probability[1] \\\n",
    "    *gauss(X[0], conditional_probability[0][1][0],conditional_probability[0][1][1])  \\\n",
    "    # *gauss(X[1], conditional_probability[1][1][0],conditional_probability[1][1][1])  \\\n",
    "    # *gauss(X[2], conditional_probability[2][1][0],conditional_probability[2][1][1])  \\\n",
    "    # *gauss(X[3], conditional_probability[3][1][0],conditional_probability[3][1][1])\n",
    "    print(p1)\n",
    "\n",
    "    # p2=prior_probability[2] \\\n",
    "    # *gauss(X[0], conditional_probability[0][2][0],conditional_probability[0][2][1])  \\\n",
    "    # *gauss(X[1], conditional_probability[1][2][0],conditional_probability[1][2][1])  \\\n",
    "    # *gauss(X[2], conditional_probability[2][2][0],conditional_probability[2][2][1])  \\\n",
    "    # *gauss(X[3], conditional_probability[3][2][0],conditional_probability[3][2][1])\n",
    "\n",
    "    # print(p0, p1)\n",
    "\n",
    "    list_p = [p0, p1]\n",
    "    # list_p = [p0, p1, p2]\n",
    "\n",
    "    return list_p.index(np.max(list_p))\n",
    "\n",
    "# prediction_play_tennis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5666666666666667, 0.12888888888888891]\n",
      "[3.733333333333333, 0.1722222222222222]\n",
      "1.2080820590230566e-06\n",
      "0.34812922367906424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 1 #########################\n",
    "X = [3.4]\n",
    "train_data = create_train_data_iris()[1:]\n",
    "new_row = np.array([\"1.8\",\"0.0\"], dtype='<U12')\n",
    "new_data = np.vstack((train_data, new_row[np.newaxis, :]))\n",
    "new_row = np.array([\"3.0\",\"1.0\"], dtype='<U12')\n",
    "new_data = np.vstack((new_data, new_row[np.newaxis, :]))\n",
    "y_unique = np.unique(new_data[:,1])\n",
    "prior_probability, conditional_probability = train_gaussian_naive_bayes(new_data)\n",
    "pred = y_unique[prediction_iris(X, prior_probability, conditional_probability)]\n",
    "# assert pred == \"Iris-virginica\"\n",
    "pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.73333333 1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.17222222, 0.        ])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_data[np.where(new_data[:,1]==\"1.0\")].astype(float).mean(axis=0))\n",
    "new_data[np.where(new_data[:,1]==\"1.0\")].astype(float).var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8, 1. ],\n",
       "       [4.1, 1. ],\n",
       "       [3.9, 1. ],\n",
       "       [4.2, 1. ],\n",
       "       [3.4, 1. ],\n",
       "       [3.8, 1. ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[np.where(new_data[:,1]==\"1.0\")].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1.4', '0.0'],\n",
       "       ['1.0', '0.0'],\n",
       "       ['1.3', '0.0'],\n",
       "       ['1.9', '0.0'],\n",
       "       ['2.0', '0.0'],\n",
       "       ['3.8', '1.0'],\n",
       "       ['4.1', '1.0'],\n",
       "       ['3.9', '1.0'],\n",
       "       ['4.2', '1.0'],\n",
       "       ['3.4', '1.0']], dtype='<U12')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
